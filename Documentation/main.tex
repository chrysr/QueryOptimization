\def\ArtDir{main/}

\documentclass{ws-ijprai}
 \usepackage[table,xcdraw]{xcolor}
 \usepackage{chngpage}
 \usepackage{fancyhdr}
 
\pagestyle{fancy}
\fancyhf{}

\rfoot{Page \thepage}
\def\ArtDir{main/}
\begin{document}

\catchline{}{}{}{}{}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}
    \centering

    \vspace*{0.5cm}

    \huge\bfseries
    Software Development for Information Systems (2019 – 2020)
    \vspace*{\fill}
    \vspace*{0.5cm}

    \large Antonis Klironomos\\[0.1in]Chrysostomos Rampidis\\[0.1in]Fotis Ektoras Tavoularis

    \vspace*{\fill}
\end{titlepage}
\clearpage
\tableofcontents
\clearpage
\newcommand\tab[1][1cm]{\hspace*{#1}}
\enlargethispage{\baselineskip}
\section{Introduction}


\tab The following study was executed as part of the course on software development for information systems in the {\it Notional and Kapodistrian University of Athens}. The aim of this study was to create a subset of a database that manages data entirely in the main memory. The whole task was split in three parts. In the first part we implemented a Sort Merge Join Algorithm, in the second one we performed a query analysis, similar to the one used in the {\it SIGMOD 2018} competition, while in the last part we implemented CPU personalization and a query optimizer.
\tab The project is hosted in GitHub (https://github.com/hectortav/Project2020) and contains a Makefile for compilation
and a bash script (testProgram.sh) to easily test the program. To run the executable, produced by the Makefile,
called "final", you can use one or more of the following flags to provide cli arguments:

\begin{itemize}
    \item \textbf{-qr}: Each query is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-ro}: If “\textbf{-pb}” argument is not provided \textbf{and} if current shift of hash function is even, the reorder task of the “overflowed” bucket is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-pb}: If “\textbf{-ro}” argument is provided, the reorder task of each “overflowed” bucket is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-qs}: Each quicksort task is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-jn}: If “-jnthreads” argument is not provided, each job is responsible for joining areas that have the same prefix.
    \item \textbf{-jnthreads}: if “\textbf{-jn}” argument is provided, the array involved in \textbf{each} join is split evenly according to the thread pool’s size and the join of each of its parts with the other array is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-pj}: The result array is split evenly according to the thread pool’s size and the calculation of the sums of each of its parts is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-ft}: Each time a filter is handled, the current array of row ids is split evenly according to the thread pool’s size and the filtering of each of its parts is scheduled as a single Job and runs in parallel with the other Jobs.
    \item \textbf{-all}: Equivalent to the following combination of arguments: \textbf{-qr -ro -qs -jn -pj -ft}
    \item \textbf{-n \textless \# of threads\textgreater}: Size of the thread pool to be created by the scheduler.
    \item \textbf{-optimize}: Join enumeration is used to reorder join predicates. \textbf{Note}: If this argument is \textbf{not} provided, join predicates are not reordered but filter predicates are relocated before the join predicates.
    \item \textbf{-h}: Displays a help message which contains a short description of each argument.
 \end{itemize}
 
\clearpage
\section{Code Description}
\subsection{Description of job scheduler and jobs (class JobScheduler & abstract class Job)}
\begin{itemize}
    \item JobScheduler consists of a queue (JobQueue) in which any kind of Job (: abstract class) is inserted.
    \item When the JobScheduler gets initialized, a thread pool is created, the size of which is defined by the user.
    \item When a new Job (with a new unique id) is inserted into the queue, an available thread or the first thread that will be available handles the Job.
    \item Job insertion and obtainment is handled with mutual exclusion in order to avoid race conditions.
    \item If the Job is a Radix-sort Job (for parallel Radix-sort) or a Quicksort Job (for parallel Quicksort), jobsCounter[queryIndex] is \textbf{incremented by 1} when the Job is inserted into the queue. This is helping the parent thread in knowing when to proceed in joining the results of the 2 relations’ reordering. (queryIndex is the index/id of the current query and it is used for the case of parallel run of queries)
    \item When \textbf{any} Job is completed, jobsCounter[queryIndex] is \textbf{decremented by 1}. If jobsCounter[queryIndex] equals to \textbf{0}, a condition variable is signaled which indicates that all the jobs of the current part of the program are done, so the parent thread can continue its execution.
    \item When the JobScheduler gets destroyed, it creates ExitJobs (with \textbf{id=-1}), the count of which is equal to the thread pool’s size. When a thread handles an ExitJob, it exits immediately.
\end{itemize}

\subsection{Description of intermediate result (class IntermediateArray)}
\begin{itemize}
    \item IntermediateArray consists of the row ids of each array (of the predicate) that took part in previous joins. Each column is identified by the corresponding predicate array’s id.
    \item After the first join, an IntermediateArray is created having as contents the 2 columns that resulted from the join.
    \item After each consecutive join, which involves a column (with row ids) of the IntermediateArray and a column (with row ids) of a first-time-used predicate array, a new IntermediateArray is created. This newly created IntermediateArray has \textbf{row count} equal to the last join result’s row count and \textbf{column count} equal to the previous IntermediateArray’s column count \textbf{plus 1}. Its contents are the joined row ids taken from the previous IntermediateArray and the joined row ids of the firstly used predicate array.
    \item A join between 2 arrays that have already been involved in a previous join, is handled as inner-join/self-join of the current IntermediateArray.

\end{itemize}

\subsection{Description of handlepredicates(), the main function of the program}
The flow of handlepredicates() is the following:
\begin{enumerate}
    \item Filter predicates are relocated before the join predicates. If “\textbf{-optimize}” argument is provided, join predicates are reordered according to an algorithm of \textbf{join enumeration}.
    \item For each predicate array id (which corresponds to an original input array (InputArray object)), a new InputArray object is created which contains \textbf{only the row ids} of the original input array. This is done because it prevents the existence of duplicated data.
    \item For each predicate:
    \begin{enumerate}
        \item If the predicate is \textbf{filter} or \textbf{self-join/inner-join} of an input array, its row ids (InputArray object) are filtered and transferred to a newly created InputArray which replaces the old row ids.
        \item If the predicate contains 2 predicate array ids both of which exist in the current IntermediateArray (both participated in a previous join), this case is handled as a \textbf{self-join/inner-join} of the current IntermediateArray. So, the current IntermediateArray is filtered and transferred to a newly created IntermediateArray which becomes the current one.
        \item In any other case, the predicate is handled as a typical join between 2 arrays. Specifically:
        \begin{enumerate}
            \item For each of the 2 pairs of predicate array id and field id, an object of type relation is created by retrieving data from the corresponding original input array. The \textbf{payloads} are retrieved from the rows the ids of which exist \textbf{(1)} in the corresponding (filtered) row-ids-array (InputArray object) \textbf{or (2)} in the current IntermediateArray if the predicate array id participated in a previous join. In case \textbf{(1)}, the \textbf{keys} of the relation are the row ids of the original input array. In case \textbf{(2)}, the \textbf{keys} of the relation are the row ids of the current IntermediateArray.
            \item For each predicate array id and field id, if the combination of them participated in the last join, the above corresponding extracted relation does \textbf{not} get reordered, because it already is. In the opposite case, the relation gets reordered with \textbf{radix-sort}.
            \item The 2 above ordered relations are joined in a list which is then converted to a 2-column array each of its columns contains the row ids of either the original input array or the current IntermediateArray as mentioned in step (i).
            \item If the result contains 0 entries, then the function does the necessary memory deallocation and returns NULL which indicates no results.
            \item In any other case, a new IntermediateArray is created which consists of only the above 2-column result if this is the first join, \textbf{or} of the contents of the previous IntermediateArray \textbf{plus} the column with the row ids of the first-time-joined InputArray. This new IntermediateArray becomes the current one.
        \end{enumerate}
        \item If the last IntermediateArray is not NULL and its size is greater than 0, the function returns it. In any other case, NULL is returned which indicates no results.
    \end{enumerate}
\end{enumerate}

\subsection{Map data structure used for the optimization algorithm}
\tab For the implementation of the optimization algorithm, a map data structure was used. This map uses a “Key” as a key and returns a “Value”. A map is a data structure that uses some information as identification for some other information. In our case, it uses a “PredicateArray” to produce another “PredicateArray” with some stats, all described in the “Value” class.

\tab The Key acts like a normal key in any other map, being unique and is the point of reference to returning a Value. A value acts like the content of a specific key. A value also contains a 2d array with statistics used by the algorithm.

\tab The functions insert and retrieve were implemented to make use of the map. Also another helping function,exists, was used to check if a specific key already exists in the map. Constructors and destructors were also implemented for correct memory management and efficient usage of the map.

\tab This map is exclusively used for calculating the best order of the predicates given, meaning that it finds the combination of predicates with the least total cost, by using formulas and specific metrics provided by the instructors of this course.


\section{Implementation Observations}

\tab We implemented and tested two different methods for sorting buckets during the first and second part. One of them was using recursion while the other one was using a loop to break the buckets into smaller ones when needed. After thorough testing we decided to use the recursive one since we managed to achieve better execution times and convolution while we also managed to keep each thread work on a different memory part at any time, reducing the need for semaphores which would slow the execution further since each thread would have to wait to access the memory.

\tab Another part of the execution that we tried to parallelize was the copy from one tuple to another during each call of the Reorder function (tuplereorder\_parallel @ functions.cpp), but we finally decided not to keep the change since it significantly slowed the program because all the extra threads that would be used to execute the copy could be used more efficiently by another function that is waiting in the scheduler.

\tab To adapt Join for running on a parallel processing system, we tried several different implementations. First, we tried the one described in class, that is to join areas that have the same prefix. Then, we tried merging some of these areas together so that each new area cluster is assigned to a thread. Finally, we tried to split the relation in equal parts so that each part is assigned to a thread. We noticed that the third method that kept the job count at a minimum while at the same time accomplished a balanced load between threads, produced a better result concerning time and processor usage.

\tab We noticed that we had great time improvements when we used smaller and continues memory allocations. For example by turning histogram and psum from 2D arrays to 1D we managed to cut the execution time to 60\% of what we had with the model described in class. The reasoning behind this great improvement is that a big part of the array can be kept in cache and we don't have to worry about loading times that take a long time.

\tab Another observation was the difference between the small and medium inputs. We noticed that the multi threading was better exploited with the medium sized input, where we saw greater time and CPU usage improvements. The explanation is that the time that it takes to split the jobs and wait for an available thread is better justified when the inputs are greater and the time relation of the thread organization processes to the time of the rest of the processes tend to zero.

\tab While running the program through a profiler, we noticed that partitioning during predicate optimization, consumed 37\% of the overall time. That means there are many data in a small number of buckets. That way we do not have the optimal outcome we could accomplish with an other optimization policy.

\tab Another observation we made is that the list functions (e.g. insert) consume 17\% of the time. If we had another data structure that would not require constant checks and processes to allocate new memory blocks we would achieve better times with probably an allocation of unneeded memory as a negative aspect.

\clearpage
\begin{samepage}
\section{Time Statistics}

\tab The following table contains the program runtime measurements, CPU and memory usage with various parameters:\\

\subsubsection{Small Sized Input}

\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{
>{\columncolor[HTML]{9AFF99}}l lllllll}
\hline
 & \cellcolor[HTML]{9AFF99}\begin{tabular}[c]{@{}l@{}}1 thread\\ (serial)\end{tabular} & \cellcolor[HTML]{9AFF99}2 threads & \cellcolor[HTML]{9AFF99}4 threads & \cellcolor[HTML]{9AFF99}8 threads & \cellcolor[HTML]{9AFF99}16 threads & \cellcolor[HTML]{9AFF99}32 threads & \cellcolor[HTML]{9AFF99}64 threads \\ \hline
No predicate optimization & 0.775 & N/A & N/A & N/A & N/A & N/A & N/A \\
Predicate optimization & 0.720 & N/A & N/A & N/A & N/A & N/A & N/A \\
\begin{tabular}[c]{@{}l@{}}(No predicate optimization)\\ Parallel queries\end{tabular} & N/A & 0.856 & 0.662 & 0.645 & 0.671 & 0.671 & 0.727 \\
\begin{tabular}[c]{@{}l@{}}(No preddicate optimization)\\ Run the following in parallel \\ (Radix-sort, Quicksort, \\ Join, Filters, Projection)\end{tabular} & N/A & 0.841 & 0.837 & 0.856 & 0.890 & 0.914 & 0.906 \\
\begin{tabular}[c]{@{}l@{}}(No predicate optimization) \\ Everything runs in parallel\\ (Queries, Radix-sort, \\ Quicksort, Join, \\ Filters, Projection)\end{tabular} & N/A & 0.889 & 0.806 & 0.744 & 0.719 & 0.737 & 0.785 \\
\begin{tabular}[c]{@{}l@{}}(Predicate optimization) \\ Parallel queries\end{tabular} & N/A & 0.780 & 0.645 & 0.673 & 0.670 & 0.631 & 0.649 \\
\begin{tabular}[c]{@{}l@{}}(Preddicate optimization) \\ Run the following in parallel \\ (Radix-sort, Quicksort, \\ Join, Filters, Projection)\end{tabular} & N/A & 0.788 & 0.772 & 0.802 & 0.833 & 0.983 & 0.861 \\
\begin{tabular}[c]{@{}l@{}}(Predicate optimization) \\ Everything runs in parallel \\ (Queries, Radix-sort, \\ Quicksort, Join, \\ Filters, Projection)\end{tabular} & N/A & 0.825 & 0.738 & 0.707 & 0.652 & 0.690 & 0.701 \\ \hline
\end{tabular}%
}
\caption{}
\caption{Time in seconds}
\label{tab:my-table}
\end{table}
\end{samepage}
\clearpage
\subsubsection{Medium Sized Input}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}
\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{
>{\columncolor[HTML]{9AFF99}}l lllllll}
\hline
 & \cellcolor[HTML]{9AFF99}\begin{tabular}[c]{@{}l@{}}1 thread\\ (serial)\end{tabular} & \cellcolor[HTML]{9AFF99}2 threads & \cellcolor[HTML]{9AFF99}4 threads & \cellcolor[HTML]{9AFF99}8 threads & \cellcolor[HTML]{9AFF99}16 threads & \cellcolor[HTML]{9AFF99}32 threads & \cellcolor[HTML]{9AFF99}64 threads \\ \hline
No predicate optimization & 47.211 & N/A & N/A & N/A & N/A & N/A & N/A \\
Predicate optimization & 48.311 & N/A & N/A & N/A & N/A & N/A & N/A \\
\begin{tabular}[c]{@{}l@{}}(No predicate optimization)\\ Parallel queries\end{tabular} & N/A & 44.903 & 24.862 & 20.573 & 20.471 & 20.844 & 21.023 \\
\begin{tabular}[c]{@{}l@{}}(No preddicate optimization)\\ Run the following in parallel \\ (Radix-sort, Quicksort, \\ Join, Filters, Projection)\end{tabular} & N/A & 41.879 & 38.320 & 37.520 & 38.142 & 36.670 & 38.874 \\
\begin{tabular}[c]{@{}l@{}}(No predicate optimization) \\ Everything runs in parallel\\ (Queries, Radix-sort, \\ Quicksort, Join, \\ Filters, Projection)\end{tabular} & N/A & 47.957 & 35.500 & 29.447 & 20.235 & 20.767 & 22.356 \\
\begin{tabular}[c]{@{}l@{}}(Predicate optimization) \\ Parallel queries\end{tabular} & N/A & 47.957 & 25.203 & 20.961 & 20.235 & 20.767 & 22.356 \\
\begin{tabular}[c]{@{}l@{}}(Preddicate optimization) \\ Run the following in parallel \\ (Radix-sort, Quicksort, \\ Join, Filters, Projection)\end{tabular} & N/A & 46.076 & 23.769 & 20.072 & 20.854 & 21.316 & 21.008 \\
\begin{tabular}[c]{@{}l@{}}(Predicate optimization) \\ Everything runs in parallel \\ (Queries, Radix-sort, \\ Quicksort, Join, \\ Filters, Projection)\end{tabular} & N/A & 38.684 & 32.924 & 30.747 & 30.871 & 31.293 & 36.182 \\ \hline
\end{tabular}%
}
\caption{}
\caption{Time in seconds}
\label{tab:my-table}
\end{table}
\clearpage
\section{Time Results Conclusions}
\begin{itemize}
    \item Without the “-optimize” flag the program runs without query optimization \textbf{but with the filters of each query being placed first}. This is a reason why sometimes the program runs quicker without the “-optimize” flag. 	
    \item When 	the small dataset is given as input, the size of the data is so small that the overhead of Join Enumeration adds a \textbf{small} delay to the program compared to its execution without the “-optimize” flag.
    \item When 	the \textbf{medium} dataset is given as input, the size of the data is bigger, so Join Enumeration increases the speed of the program.
    \item Parallelism increases the speed of the program significantly because the execution load is split so that each thread is handling a different Job at each given moment.
    \item When the program’s thread pool has a size which is larger than the maximum number of threads that the system can provide, there is only a small or no amount of increase at the program’s speed compared to using a smaller thread pool.
\end{itemize}

\section{Parallelization Observations}
\tab At the third and last part of the project, parallelization was added to the program. The effect this transition had on the program is immediately apparent when looking at the overall execution times. Adding CPU parallelization led to a decline of 60\% concerning execution time and a increase of 70\% concerning CPU usage which means computer resources are better utilized and the overall outcome is maximized.

\section{Version Control Observations}
\tab During the whole project we used git as a version control system. With git we managed to track bugs that emerged during development and then easily solve them. Git also helped our team to share code and communicate better that led to better organization and management. Finally, a git aspect we found greatly useful was branching since each team member could work in separate features without causing problems and interference.

\clearpage
\section{Unit Testing}

\tab To test the execution of our program we used unit testing and especially Cunit. We tried to make unit tests for every function regardless of the size or simplicity. Some of the functions tested are the following: 
\begin{itemlist}
\item randomIndex
\item swap
\item hashFunction
\item makeparts
\item splitpreds
\item optimizepredicates
\item predsplittoterms
\item sortBucket
\item histcreateTest
\item psumcreateTest
\item tuplesReorderTest
\item InputArray::filterRowIds
\item InputArray::extractColumnFromRowIds
\item IntermediateArray::populate
\item IntermediateArray::findColumnIndexByInputArrayId
\item IntermediateArray::findColumnIndexByPredicateArrayId
\item IntermediateArray::selfJoin
\end{itemlist}
\tab Overall we concluded that unit testing in an easy way to test and validate the solidity of a big project, that would otherwise require many hours of manual testing. Also we found that creating unit tests before the project is a valid way to ensure the smooth development of a program as well as keeping the team in track and necessitate the usage of a common API.

\section{Conclusion}

\tab During this assignment we used various technologies and researched a plethora of ideas and theories. We appreciated concepts like parallel programming, unit testing, version control and of course software development for information systems. Parallel programming is a useful asset today since all systems have multiple real and virtual CPU cores that are not often utilized correctly. Unit testing is a respectful way to ensure that programs \& algorithms are valid and ready for production and version control is an easy way to track bugs and work with teams. Information systems and databases are the core of today's computing and leaving in an age where data are abundant, we must explore new and more efficient ways to store, find and index them. Last but not least, we learned the importance of pre-planning, estimating possible obstacles and chances during development of such last projects.
%profiler, data size, parallelization, git, unit testing, local memory, data bases, bucket sorting
%sxediash kai planning
\end{document}